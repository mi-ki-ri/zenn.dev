---
title: "transformers.jsã‚’ä½¿ã£ã¦ãƒ­ãƒ¼ã‚«ãƒ«ã§LLMã‚’å‹•ã‹ã™ã¨ã„ã†é‡æœ›" # è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«
emoji: "ğŸ¤–" # ã‚¢ã‚¤ã‚­ãƒ£ãƒƒãƒã¨ã—ã¦ä½¿ã‚ã‚Œã‚‹çµµæ–‡å­—ï¼ˆ1æ–‡å­—ã ã‘ï¼‰
type: "tech" # tech: æŠ€è¡“è¨˜äº‹ / idea: ã‚¢ã‚¤ãƒ‡ã‚¢è¨˜äº‹
topics: ["transformers", "AI", "transformersjs", "nodejs"] # ã‚¿ã‚°ã€‚["markdown", "rust", "aws"]ã®ã‚ˆã†ã«æŒ‡å®šã™ã‚‹
published: true # å…¬é–‹è¨­å®šï¼ˆfalseã«ã™ã‚‹ã¨ä¸‹æ›¸ãï¼‰
---

## ã‚ã‚‰ã¾ã—

ãƒãƒƒãƒˆã‚µãƒ¼ãƒ•ã‚£ãƒ³ã—ã¦ã„ãŸã‚‰ [transformers.js](https://huggingface.co/docs/transformers.js/index)ã¨ã„ã†ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’è¦‹ã¤ã‘ã¾ã—ãŸã€‚

ã“ã‚Œã¯ Python ã® transformers ã¨åŒã˜ã‚ˆã†ãªæ©Ÿèƒ½ã‚’ JS ã§æä¾›ã—ã¦ã„ã‚‹ã‚‚ã®ã§ã€ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚‚å‹•ãã‚‰ã—ã„ã§ã™ã€‚ã™ã”ã„ã€‚

ç”Ÿæˆ AI ã‚’ä½¿ã£ãŸã‚¢ãƒ—ãƒªã‚’é–‹ç™ºã—ã‚ˆã†ã¨æ€ã£ãŸã‚‰ã‚³ã‚¹ãƒˆã¯å•é¡Œã«ãªã‚Šã¾ã™ã€‚

ã‚ã‚‹ã„ã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ã« OPENAI ãªã©ã® API_KEY ã‚’å–å¾—ã—ã¦ã‚‚ã‚‰ã†æ‰‹ã‚‚ã‚ã‚Šã¾ã™ãŒã€åˆå¿ƒè€…ã«ã¯é›£ã—ã„ã§ã™ã€‚

ã—ã‹ã—ãƒ–ãƒ©ã‚¦ã‚¶ã§ç”Ÿæˆ AI ã‚’å‹•ã‹ã›ã‚Œã°ã‚³ã‚¹ãƒˆã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒã¡ã«ãªã‚Šã€ã‚­ãƒ¼ã®å–å¾—ã®ã‚ˆã†ãªæ‰‹ç¶šãã‚‚å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚

ã„ã„äº‹ãšãã‚ãªã®ã§è©¦ã—ã¦ã¿ã¾ã—ãŸã€‚

ç›®æ¨™ã¯ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’ç”Ÿæˆã™ã‚‹ã“ã¨ã§ã™ã€‚

ã‚ã¨ä»Šå›ã¯ã¾ã ãƒ–ãƒ©ã‚¦ã‚¶ã§ã¯ãªããƒ­ãƒ¼ã‚«ãƒ«ã® nodejs ç’°å¢ƒã§ã™ã€‚

```txt
ä»Šæ—¥ã¯å¤§ãã„çŠ¬ã‚’è¦‹ã¾ã—ãŸã€‚
```

ä¸Šã®ã‚ˆã†ãªãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ã€

```js
[{ tag: "çŠ¬" }, { tag: "å¤§ãã„" }, { tag: "ã‚¢ãƒ‹ãƒãƒ«" }];
```

ã“ã†ã„ã†é…åˆ—ã‚’ã‚²ãƒƒãƒˆã—ãŸã„ã€‚

[JavaScript ã§ LLM ã‚’å¼„ã£ã¦ã¿ã‚‹ã€transformers.jsã€‘](https://zenn.dev/saldra/articles/44bc401e773a62)ã‚’å‚è€ƒã«ã•ã›ã¦ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚

## ãƒ¢ãƒ‡ãƒ«ã®ã‚³ãƒ³ãƒãƒ¼ãƒˆ

ã“ã® transformers.js ã¯ ONNX ã¨ã„ã†å½¢å¼ã®ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚€ã‚ˆã†ã«ãªã£ã¦ã„ã¾ã™ã€‚

æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆãƒ¢ãƒ‡ãƒ«ã® ELYZA ã‚’ä½¿ã„ãŸã‹ã£ãŸã®ã§ã€ã²ã¨ã¾ãšã‚³ãƒ³ãƒãƒ¼ãƒˆã‚’ã‹ã‘ã¦ã¿ã¾ã™ã€‚

ã‚³ãƒ³ãƒãƒ¼ãƒˆç”¨ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¯[å…¬å¼ãƒªãƒã‚¸ãƒˆãƒª](https://github.com/xenova/transformers.js)ã®ä¸­ã« scripts ã¨ã—ã¦å…¥ã£ã¦ã„ã¾ã™ã€‚

```bash
python -m venv venv
. ./venv/bin/activate
pip install -r scripts/requirements.txt
python -m scripts.convert --quantize --model_id <model_name_or_path>
```

ã“ã‚“ãªæ„Ÿã˜ã§ã‚³ãƒ³ãƒãƒ¼ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’èµ°ã‚‰ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

### ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒç„¡ã„ã‚¨ãƒ©ãƒ¼

ELYZA ã®å ´åˆã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒç„¡ã„ã¨ã‹ã„ã†ã‚¨ãƒ©ãƒ¼ãŒå‡ºã¾ã™ã€‚

è»½å¾®ãªã‚¨ãƒ©ãƒ¼ã ã¨æ€ã£ãŸã®ã§ convert.py ã‚’ **ç›´ã«ã„ã˜ã£ã¦** è§£æ±ºã—ã¾ã—ãŸã€‚

`scripts/convert.py`ã® 336 è¡Œç›®ã‚ãŸã‚Šã€

```python
# setattr(tokenizer, 'chat_template', tokenizer.default_chat_template) # ã“ã‚Œã ã¨ã‚¨ãƒ©ãƒ¼
setattr(tokenizer, "chat_template", "") # ã—ã‹ãŸãªãç©ºç™½ã‚’å…¥ã‚Œã‚‹
```

ã“ã®ã‚ˆã†ãªã“ã¨ã‚’ã—ã¦ã‚¨ãƒ©ãƒ¼ã‚’å¼·å¼•ã«é®ã‚ã¾ã—ãŸã€‚

### è‡ªåˆ†ã®ç’°å¢ƒã§ã¯å¤±æ•—

ãŒã€çµå±€è‡ªåˆ†ã®ç’°å¢ƒ(Macbook)ã§ã¯ã†ã¾ãã‚³ãƒ³ãƒãƒ¼ãƒˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚

æ™®é€šã®ã‚³ãƒ³ãƒãƒ¼ãƒˆã¯ã§ãã‚‹ã®ã§ã™ãŒã€Quantize ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã¯å‡ºã¦ã“ãªã„ã®ã§ã™ã€‚

GPU ã®å•é¡Œã‹ã€CUDA ã®å•é¡Œã®ã‚ˆã†ã§ã™â€¦â€¦ã€‚

ä»•æ–¹ãªãã‚ã‚Šã‚‚ã®ã‚’ä½¿ã£ã¦ã¿ã¾ã™ã€‚

## ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ

### rinna ã®å ´åˆ

ä¸Šè¨˜ saldra ã•ã‚“ã®è¨˜äº‹ã®"saldra/rinna-japanese-gpt2-xsmall-onnx"ã‚’åˆ©ç”¨ã—ã¦ã¿ã¾ã—ãŸã€‚

```js
import { env, pipeline } from "@xenova/transformers";
env.allowLocalModels = false;
env.localModelPath = "models/";

let generator = await pipeline(
  "text-generation",
  "saldra/rinna-japanese-gpt2-xsmall-onnx"
);
let result = await generator(
  "ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã«é©åˆ‡ãªãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’ã¤ã‘ã¦ãã ã•ã„ã€‚\n\n<text>ä»Šæ—¥ã¯å¤§ãã„çŠ¬ã‚’è¦‹ã¾ã—ãŸã€‚</text>"
);
console.log(result);
```

ä¸Šè¨˜ã®ã‚ˆã†ãª JS ã‚’æ›¸ã„ã¦å®Ÿè¡Œã—ã¦ã¿ã¾ã—ãŸã€‚

ç’°å¢ƒã¯ãƒ­ãƒ¼ã‚«ãƒ«ã® node ãªã®ã§ãƒ–ãƒ©ã‚¦ã‚¶ã§ã¯æœ‰ã‚Šã¾ã›ã‚“ãŒã€åŸç†çš„ã«ã¯åŒã˜ã¯ãšã€‚

```bash
[
  {
    generated_text: 'ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã«é©åˆ‡ãªãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’ã¤ã‘ã¦ãã ã•ã„ã€‚ <text>ä»Šæ—¥ã¯å¤§ãã„çŠ¬ã‚’è¦‹ã¾ã—ãŸã€‚</text>'
  }
]
```

è¿”ç­”ã¯è¿”ã£ã¦ããŸã‘ã©ã€ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã¯ç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚ªã‚¦ãƒ è¿”ã—çš„ãªâ€¦â€¦ã€‚

### TinyLlama-1.1B-Chat ã®å ´åˆ

åˆ¥ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ¢ã—ã¦ã¿ã¾ã—ãŸã€‚

[https://huggingface.co/models](https://huggingface.co/models)ã®å·¦ãƒšã‚¤ãƒ³ã«ã‚ã‚‹çµã‚Šè¾¼ã¿ã‚’åˆ©ç”¨ã—ã¦ text-generation ã§ ONNX ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã„ãã¤ã‹æ¢ã—ã¦ã¿ã¾ã™ã€‚

æ—¥æœ¬èªãƒ¢ãƒ‡ãƒ«ã§ã¯ãªã„ã®ã§ã€è‹±èªã§ã®å…¥åŠ›ã«ãªã‚Šã¾ã™ã€‚

TinyLlama 1.1B-Chat ã® ONNX ç‰ˆãŒã‚ã£ãŸã®ã§ã€ä½¿ã‚ã›ã¦ã‚‚ã‚‰ã„ã¾ã—ãŸã€‚

```js
import { pipeline, env } from "@xenova/transformers";
env.allowLocalModels = true;
env.localModelPath = "models/";

const modelName = "Xenova/TinyLlama-1.1B-Chat-v1.0";
const generator = await pipeline("text-generation", modelName);

// Define the list of messages
const messages = [
  { role: "system", content: "you're a instagram tagging ai." },
  { role: "system", content: "please tagging following text for instagram." },
  {
    role: "system",
    content:
      "answer is JSON format, like[{tag: 'dog'},{tag: 'cat'},{tag: 'animal'}]",
  },
  {
    role: "user",
    content: "this is my dog.",
  },
];

// Construct the prompt
const prompt = generator.tokenizer.apply_chat_template(messages, {
  tokenize: false,
  add_generation_prompt: true,
});

// Generate a response
const result = await generator(prompt, {
  temperature: 2,
});
console.log(result);
```

```bash
[
  {
    generated_text: '<|system|>\n' +
      "you're a instagram tagging ai.\n" +
      '<|system|>\n' +
      'please tagging following text for instagram.\n' +
      '<|system|>\n' +
      "answer is JSON format, like[{tag: 'dog'},{tag: 'cat'},{tag: 'animal'}]\n" +
      '<|user|>\n' +
      'this is my dog.\n' +
      '<|assistant|>\n' +
      'please tagging following text for instagram.'
  }
]
```

ã—ã‹ã—ã‚ªã‚¦ãƒ è¿”ã—ç™–ã¯ç›´ã‚‰ãšâ€¦â€¦ã€‚

## çµè«–

ä½•ã‹ãŒè¶³ã‚Šãªã„ã®ã ã¨æ€ã†ã®ã§ã€ã‚‚ã†å°‘ã—æŠ€è¡“ã®ç™ºå±•ã‚’å¾…ã¤ã“ã¨ã«ã—ã¾ã™ã€‚
